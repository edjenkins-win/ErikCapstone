{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AI-Powered Photo Editing: Intelligent Image Enhancement\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Photo editing traditionally requires significant technical knowledge and artistic skill. Users need to understand complex concepts like exposure, contrast, color balance, and composition to achieve professional-looking results. This creates a high barrier to entry for casual photographers who want to enhance their images but lack the technical expertise.\n",
    "\n",
    "Additionally, the editing process can be time-consuming, requiring multiple adjustments and trial-and-error to achieve the desired look. This is especially challenging when dealing with different types of images (landscapes, portraits, low-light scenes) that each require specialized editing approaches.\n",
    "\n",
    "## How Generative AI Solves This Problem\n",
    "\n",
    "Generative AI transforms the photo editing experience by bringing intelligence and automation to the process. Instead of requiring users to understand technical details, AI can:\n",
    "\n",
    "1. **Analyze image content** to understand what's in the photo (people, landscapes, objects)\n",
    "2. **Assess technical qualities** like lighting conditions, color balance, and exposure\n",
    "3. **Recommend appropriate adjustments** based on the specific content and conditions\n",
    "4. **Understand natural language instructions** from users who can describe what they want in plain English\n",
    "5. **Suggest cinematic styles** that match the image content using knowledge of cinematography techniques\n",
    "\n",
    "This notebook demonstrates how our AI Photo Editor uses these capabilities to make professional-quality editing accessible to everyone, regardless of technical expertise.\n"
   ],
   "id": "347054ffdfee7384"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment.\n"
   ],
   "id": "d4ee40ad4373ec15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Import our photo editing package\n",
    "from photoedit_mvp import (\n",
    "    load_image, \n",
    "    save_image, \n",
    "    analyze_image, \n",
    "    apply_adjustments\n",
    ")\n",
    "\n",
    "# Import AI-specific modules\n",
    "from photoedit_mvp.ai_analyzer import AIImageAnalyzer\n",
    "from photoedit_mvp.nl_processor import NLProcessor\n",
    "from photoedit_mvp.rag_style_engine import RAGStyleEngine\n",
    "\n",
    "# Set up matplotlib for displaying images\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n"
   ],
   "id": "97a7729853c2fd22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's define some helper functions to display images and results.\n"
   ],
   "id": "7b0e0912ecf17fa6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def display_image(image, title=None):\n",
    "    \"\"\"Display an image with an optional title.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if isinstance(image, str):\n",
    "        # If image is a file path, load it\n",
    "        image = load_image(image)\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        plt.title(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def display_before_after(before, after, titles=None):\n",
    "    \"\"\"Display before and after images side by side.\"\"\"\n",
    "    if titles is None:\n",
    "        titles = ['Before', 'After']\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    if isinstance(before, str):\n",
    "        before = load_image(before)\n",
    "    plt.imshow(before)\n",
    "    plt.axis('off')\n",
    "    plt.title(titles[0], fontsize=14)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    if isinstance(after, str):\n",
    "        after = load_image(after)\n",
    "    plt.imshow(after)\n",
    "    plt.axis('off')\n",
    "    plt.title(titles[1], fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_multiple(images, titles=None, cols=3):\n",
    "    \"\"\"Display multiple images in a grid.\"\"\"\n",
    "    n = len(images)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    \n",
    "    plt.figure(figsize=(5*cols, 5*rows))\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        if isinstance(image, str):\n",
    "            image = load_image(image)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        if titles and i < len(titles):\n",
    "            plt.title(titles[i], fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "8a611c0260157852"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. AI-Powered Image Analysis\n",
    "\n",
    "One of the key innovations in our photo editor is the ability to analyze image content using AI. This allows the application to understand what's in the photo and make intelligent recommendations based on the content.\n",
    "\n",
    "Let's load a test image and see what our AI analyzer can tell us about it.\n"
   ],
   "id": "b8c7d2ea3c0f41c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load a test image\n",
    "test_image_path = '../test_images/test_image.jpg'\n",
    "image = load_image(test_image_path)\n",
    "\n",
    "# Display the image\n",
    "display_image(image, \"Test Image\")\n"
   ],
   "id": "c4b6929a686290a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's use our AI analyzer to understand what's in this image.\n",
   "id": "80d371bc36f93acf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the AI image analyzer\n",
    "ai_analyzer = AIImageAnalyzer()\n",
    "\n",
    "# Analyze the image\n",
    "adjustments, analysis = ai_analyzer.analyze(image)\n",
    "\n",
    "# Display the analysis results\n",
    "print(\"AI Image Analysis Results:\")\n",
    "print(f\"Scene Type: {analysis['scene_type']}\")\n",
    "print(f\"Lighting Condition: {analysis['lighting_condition']}\")\n",
    "print(f\"Faces Detected: {analysis['face_count']}\")\n",
    "print(\"\\nDetected Objects:\")\n",
    "for obj in analysis['objects']:\n",
    "    print(f\"- {obj['class']} (confidence: {obj['confidence']:.2f})\")\n",
    "\n",
    "print(\"\\nDominant Colors:\")\n",
    "for i, color in enumerate(analysis['color_palette'][:3]):\n",
    "    print(f\"- Color {i+1}: RGB{tuple(color)}\")\n",
    "\n",
    "print(\"\\nRecommended Adjustments:\")\n",
    "for adj in adjustments:\n",
    "    print(f\"- {adj.parameter}: {adj.suggested} {adj.unit} - {adj.description}\")\n"
   ],
   "id": "1780bca56adced2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing the AI Analysis\n",
    "\n",
    "Let's visualize some of the analysis results to better understand what the AI is seeing.\n"
   ],
   "id": "404bf9937feb6332"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize the color palette\n",
    "def display_color_palette(colors):\n",
    "    \"\"\"Display the color palette as color swatches.\"\"\"\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i, color in enumerate(colors):\n",
    "        plt.subplot(1, len(colors), i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow([[color]])\n",
    "        plt.title(f\"RGB{tuple(color)}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Dominant Color Palette:\")\n",
    "display_color_palette(analysis['color_palette'][:5])\n"
   ],
   "id": "437f6914733a0798"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Applying AI-Recommended Adjustments\n",
    "\n",
    "Now that we have AI-recommended adjustments, let's apply them to the image and see the results.\n"
   ],
   "id": "86389a05bf849a45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply the recommended adjustments\n",
    "adjusted_image = apply_adjustments(image, adjustments)\n",
    "\n",
    "# Display before and after\n",
    "display_before_after(image, adjusted_image, [\"Original Image\", \"AI-Enhanced Image\"])\n"
   ],
   "id": "512639892740bff1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Natural Language Photo Editing\n",
    "\n",
    "Another innovative feature of our photo editor is the ability to edit photos using natural language instructions. This allows users to describe what they want in plain English, without needing to understand technical terms or complex editing tools.\n",
    "\n",
    "Let's see how this works.\n"
   ],
   "id": "67f5f4676d40833d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the natural language processor\n",
    "nl_processor = NLProcessor()\n",
    "\n",
    "# Register some example functions\n",
    "# In a real implementation, these would be actual image processing functions\n",
    "def adjust_exposure(image, amount):\n",
    "    \"\"\"Adjust image exposure.\"\"\"\n",
    "    # Simple implementation for demonstration\n",
    "    result = image.copy().astype(float)\n",
    "    result = result * (1 + amount)\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "def adjust_contrast(image, multiplier):\n",
    "    \"\"\"Adjust image contrast.\"\"\"\n",
    "    # Simple implementation for demonstration\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    result = image.copy().astype(float)\n",
    "    for i in range(3):\n",
    "        result[:,:,i] = (result[:,:,i] - mean[i]) * multiplier + mean[i]\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "def adjust_saturation(image, adjustment):\n",
    "    \"\"\"Adjust image saturation.\"\"\"\n",
    "    # Convert to HSV, adjust S channel, convert back to RGB\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(float)\n",
    "    hsv[:,:,1] = hsv[:,:,1] * (1 + adjustment)\n",
    "    hsv[:,:,1] = np.clip(hsv[:,:,1], 0, 255)\n",
    "    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def adjust_temperature(image, adjustment):\n",
    "    \"\"\"Adjust image color temperature.\"\"\"\n",
    "    # Simple implementation - increase red for warmth, blue for coolness\n",
    "    result = image.copy().astype(float)\n",
    "    if adjustment > 0:  # Warm\n",
    "        result[:,:,0] = np.clip(result[:,:,0] * (1 + adjustment), 0, 255)  # Red\n",
    "        result[:,:,2] = np.clip(result[:,:,2] * (1 - adjustment/2), 0, 255)  # Blue\n",
    "    else:  # Cool\n",
    "        result[:,:,2] = np.clip(result[:,:,2] * (1 - adjustment), 0, 255)  # Blue\n",
    "        result[:,:,0] = np.clip(result[:,:,0] * (1 + adjustment/2), 0, 255)  # Red\n",
    "    return result.astype(np.uint8)\n",
    "\n",
    "# Register these functions with the NL processor\n",
    "nl_processor.register_function(\n",
    "    \"adjust_exposure\",\n",
    "    adjust_exposure,\n",
    "    \"Adjust the brightness/exposure of the image\",\n",
    "    {\"amount\": {\"type\": \"number\", \"description\": \"Amount to adjust exposure (-1.0 to 1.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_contrast\",\n",
    "    adjust_contrast,\n",
    "    \"Adjust the contrast of the image\",\n",
    "    {\"multiplier\": {\"type\": \"number\", \"description\": \"Contrast multiplier (0.5 to 2.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_saturation\",\n",
    "    adjust_saturation,\n",
    "    \"Adjust the color saturation of the image\",\n",
    "    {\"adjustment\": {\"type\": \"number\", \"description\": \"Saturation adjustment (-1.0 to 1.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_temperature\",\n",
    "    adjust_temperature,\n",
    "    \"Adjust the color temperature (warmth/coolness) of the image\",\n",
    "    {\"adjustment\": {\"type\": \"number\", \"description\": \"Temperature adjustment (-0.5 to 0.5)\"}}\n",
    ")\n"
   ],
   "id": "b39ebdb698d26cd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's try editing our image using natural language instructions.\n",
   "id": "dcfb61227a1c8fee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Process a natural language instruction\n",
    "instruction = \"Make the image warmer and increase the contrast slightly\"\n",
    "print(f\"Instruction: '{instruction}'\")\n",
    "\n",
    "# Process the instruction\n",
    "processed_image, metadata = nl_processor.process(image, instruction)\n",
    "\n",
    "# Display the functions that were called\n",
    "print(\"\\nFunctions called:\")\n",
    "for func_call in metadata['functions_called']:\n",
    "    print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "\n",
    "# Display before and after\n",
    "display_before_after(image, processed_image, [\"Original Image\", f\"After: '{instruction}'\"])\n"
   ],
   "id": "fe751c32218ed900"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's try a few more natural language instructions to see how the system responds to different requests.\n",
   "id": "5e13ae0de608285d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Try different instructions\n",
    "instructions = [\n",
    "    \"Make the colors more vibrant\",\n",
    "    \"Make the image cooler and increase contrast\",\n",
    "    \"Brighten the image and add warmth\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "titles = [\"Original\"]\n",
    "\n",
    "# Process each instruction\n",
    "for instruction in instructions:\n",
    "    processed, metadata = nl_processor.process(image, instruction)\n",
    "    results.append(processed)\n",
    "    titles.append(f\"'{instruction}'\")\n",
    "    \n",
    "    print(f\"\\nInstruction: '{instruction}'\")\n",
    "    print(\"Functions called:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "\n",
    "# Display all results\n",
    "display_multiple([image] + results, titles)\n"
   ],
   "id": "119122ddec651d98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. RAG-Based Style Recommendations\n",
    "\n",
    "Our photo editor also uses Retrieval Augmented Generation (RAG) to recommend cinematic styles based on image content. This combines a knowledge base of cinematography techniques with AI image analysis to suggest styles that match the content of the photo.\n",
    "\n",
    "Let's see how this works.\n"
   ],
   "id": "9b2092e015fa6cc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the RAG style engine\n",
    "rag_engine = RAGStyleEngine()\n",
    "\n",
    "# Get style recommendations based on image content\n",
    "recommendations = rag_engine.recommend_style(image)\n",
    "\n",
    "# Display the recommendations\n",
    "print(\"Style Recommendations Based on Image Content:\")\n",
    "for i, rec in enumerate(recommendations):\n",
    "    print(f\"\\n{i+1}. {rec['style']} (Score: {rec['score']})\")\n",
    "    print(f\"   Description: {rec['description']}\")\n",
    "    print(f\"   Reasoning:\")\n",
    "    for reason in rec['reasoning']:\n",
    "        print(f\"   - {reason}\")\n"
   ],
   "id": "38cf785815ee26aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's apply these recommended styles to our image and see the results.\n",
   "id": "198ebfde98162ba3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply the recommended styles\n",
    "styled_images = []\n",
    "style_names = []\n",
    "\n",
    "for rec in recommendations:\n",
    "    style_name = rec['style']\n",
    "    styled = rag_engine.apply_style(image, style_name)\n",
    "    styled_images.append(styled)\n",
    "    style_names.append(style_name)\n",
    "\n",
    "# Display the original and styled images\n",
    "display_multiple([image] + styled_images, [\"Original\"] + style_names)\n"
   ],
   "id": "d2859d4bc220d1b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Style Recommendations Based on Description\n",
    "\n",
    "We can also recommend styles based on a description provided by the user. This allows users to describe the look they want in natural language, and the system will find matching styles.\n"
   ],
   "id": "bec03065b06d8198"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get style recommendations based on a description\n",
    "description = \"I want a dramatic movie look with high contrast\"\n",
    "desc_recommendations = rag_engine.recommend_style(image, description)\n",
    "\n",
    "# Display the recommendations\n",
    "print(f\"Style Recommendations Based on Description: '{description}'\")\n",
    "for i, rec in enumerate(desc_recommendations):\n",
    "    print(f\"\\n{i+1}. {rec['style']} (Score: {rec['score']})\")\n",
    "    print(f\"   Description: {rec['description']}\")\n",
    "    print(f\"   Reasoning:\")\n",
    "    for reason in rec['reasoning']:\n",
    "        print(f\"   - {reason}\")\n"
   ],
   "id": "bf5e7ffe8c82d02d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's apply these description-based style recommendations.\n",
   "id": "ba48c0a404114ab7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply the description-based recommended styles\n",
    "desc_styled_images = []\n",
    "desc_style_names = []\n",
    "\n",
    "for rec in desc_recommendations:\n",
    "    style_name = rec['style']\n",
    "    styled = rag_engine.apply_style(image, style_name)\n",
    "    desc_styled_images.append(styled)\n",
    "    desc_style_names.append(style_name)\n",
    "\n",
    "# Display the original and styled images\n",
    "display_multiple([image] + desc_styled_images, [\"Original\"] + desc_style_names)\n"
   ],
   "id": "2500b7855b4e46b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Innovative Use Case: AI-Guided Creative Photography\n",
    "\n",
    "Now let's explore an innovative use case that combines all of these AI capabilities: AI-guided creative photography. In this scenario, the AI analyzes an image, suggests creative directions, and helps the user achieve a specific artistic vision.\n",
    "\n",
    "This approach is particularly valuable for:\n",
    "- Amateur photographers looking to achieve professional results\n",
    "- Creative professionals seeking inspiration\n",
    "- Educators teaching photography and editing techniques\n",
    "\n",
    "Let's see how this works in practice.\n"
   ],
   "id": "dafc36203fbd6c9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def ai_guided_creative_workflow(image, creative_direction):\n",
    "    \"\"\"Demonstrate an AI-guided creative workflow.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        creative_direction: Description of the desired creative direction\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (final image, workflow steps)\n",
    "    \"\"\"\n",
    "    workflow_steps = []\n",
    "    results = [image.copy()]\n",
    "    \n",
    "    # Step 1: Analyze the image\n",
    "    ai_analyzer = AIImageAnalyzer()\n",
    "    adjustments, analysis = ai_analyzer.analyze(image)\n",
    "    \n",
    "    workflow_steps.append({\n",
    "        \"step\": \"Image Analysis\",\n",
    "        \"description\": f\"AI analyzed the image and identified it as a {analysis['scene_type']} scene with {analysis['lighting_condition']} lighting.\"\n",
    "    })\n",
    "    \n",
    "    # Step 2: Apply basic adjustments\n",
    "    basic_adjusted = apply_adjustments(image, adjustments)\n",
    "    results.append(basic_adjusted)\n",
    "    \n",
    "    workflow_steps.append({\n",
    "        \"step\": \"Basic Adjustments\",\n",
    "        \"description\": f\"Applied {len(adjustments)} AI-recommended adjustments to optimize the image.\"\n",
    "    })\n",
    "    \n",
    "    # Step 3: Find styles matching the creative direction\n",
    "    rag_engine = RAGStyleEngine()\n",
    "    style_recs = rag_engine.recommend_style(image, creative_direction)\n",
    "    \n",
    "    if style_recs:\n",
    "        # Apply the top recommended style\n",
    "        top_style = style_recs[0]['style']\n",
    "        styled_image = rag_engine.apply_style(basic_adjusted, top_style)\n",
    "        results.append(styled_image)\n",
    "        \n",
    "        workflow_steps.append({\n",
    "            \"step\": \"Style Application\",\n",
    "            \"description\": f\"Applied '{top_style}' style based on the creative direction: '{creative_direction}'\"\n",
    "        })\n",
    "    \n",
    "    # Step 4: Fine-tune with natural language processing\n",
    "    nl_processor = NLProcessor()\n",
    "    \n",
    "    # Register the same functions as before\n",
    "    nl_processor.register_function(\"adjust_exposure\", adjust_exposure, \n",
    "                                 \"Adjust the brightness/exposure of the image\",\n",
    "                                 {\"amount\": {\"type\": \"number\", \"description\": \"Amount to adjust exposure (-1.0 to 1.0)\"}})\n",
    "    \n",
    "    nl_processor.register_function(\"adjust_contrast\", adjust_contrast,\n",
    "                                 \"Adjust the contrast of the image\",\n",
    "                                 {\"multiplier\": {\"type\": \"number\", \"description\": \"Contrast multiplier (0.5 to 2.0)\"}})\n",
    "    \n",
    "    nl_processor.register_function(\"adjust_saturation\", adjust_saturation,\n",
    "                                 \"Adjust the color saturation of the image\",\n",
    "                                 {\"adjustment\": {\"type\": \"number\", \"description\": \"Saturation adjustment (-1.0 to 1.0)\"}})\n",
    "    \n",
    "    nl_processor.register_function(\"adjust_temperature\", adjust_temperature,\n",
    "                                 \"Adjust the color temperature (warmth/coolness) of the image\",\n",
    "                                 {\"adjustment\": {\"type\": \"number\", \"description\": \"Temperature adjustment (-0.5 to 0.5)\"}})\n",
    "    \n",
    "    # Generate a fine-tuning instruction based on the creative direction\n",
    "    fine_tuning_instruction = f\"Fine-tune for {creative_direction}\"\n",
    "    final_image, metadata = nl_processor.process(results[-1], fine_tuning_instruction)\n",
    "    results.append(final_image)\n",
    "    \n",
    "    workflow_steps.append({\n",
    "        \"step\": \"Fine-tuning\",\n",
    "        \"description\": f\"Applied natural language fine-tuning: '{fine_tuning_instruction}'\",\n",
    "        \"functions\": [f\"{func['name']}({', '.join([f'{k}={v}' for k, v in func['args'].items()])})\" \n",
    "                     for func in metadata['functions_called']]\n",
    "    })\n",
    "    \n",
    "    return final_image, results, workflow_steps\n"
   ],
   "id": "fd3fb8fd68bf33e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Try the AI-guided creative workflow with different creative directions\n",
    "creative_directions = [\n",
    "    \"dramatic cinematic look\",\n",
    "    \"warm vintage feel\",\n",
    "    \"professional portrait style\"\n",
    "]\n",
    "\n",
    "for direction in creative_directions:\n",
    "    print(f\"\\n\\n=== AI-Guided Creative Workflow: '{direction}' ===\\n\")\n",
    "    \n",
    "    final_image, workflow_images, steps = ai_guided_creative_workflow(image, direction)\n",
    "    \n",
    "    # Display the workflow steps\n",
    "    for i, step in enumerate(steps):\n",
    "        print(f\"\\nStep {i+1}: {step['step']}\")\n",
    "        print(f\"  {step['description']}\")\n",
    "        if 'functions' in step:\n",
    "            print(\"  Functions applied:\")\n",
    "            for func in step['functions']:\n",
    "                print(f\"  - {func}\")\n",
    "    \n",
    "    # Display the workflow images\n",
    "    step_titles = [\"Original\"] + [step[\"step\"] for step in steps]\n",
    "    display_multiple(workflow_images, step_titles)\n"
   ],
   "id": "d7388fd166449a64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how generative AI transforms the photo editing experience by making it more accessible, intelligent, and efficient. The key innovations include:\n",
    "\n",
    "1. **AI-powered image analysis** that understands content and recommends appropriate adjustments\n",
    "2. **Natural language photo editing** that allows users to describe what they want in plain English\n",
    "3. **RAG-based style recommendations** that suggest cinematic styles based on image content and user descriptions\n",
    "4. **AI-guided creative workflows** that combine these capabilities to help users achieve specific artistic visions\n",
    "\n",
    "These capabilities democratize photo editing by removing the technical barriers that traditionally made it difficult for casual photographers to achieve professional-looking results. By understanding what's in the photo and what the user wants to achieve, the AI can guide them through the editing process and help them create images that match their creative vision.\n",
    "\n",
    "The future of photo editing is not about replacing human creativity, but about augmenting it with AI that understands both the technical aspects of photography and the artistic intentions of the user."
   ],
   "id": "e06cdc0ac6a33488"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
