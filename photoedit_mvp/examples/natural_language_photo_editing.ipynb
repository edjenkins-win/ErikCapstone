{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Natural Language Photo Editing: Transforming Words into Visual Enhancements\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Traditional photo editing interfaces rely on technical sliders, complex terminology, and specialized knowledge that can be intimidating for casual users. Even with simplified consumer apps, users must:\n",
    "\n",
    "1. Understand what each control does (exposure, contrast, saturation, etc.)\n",
    "2. Know which adjustments to make for specific visual goals\n",
    "3. Make multiple trial-and-error attempts to achieve desired results\n",
    "4. Remember which combinations of settings create specific looks\n",
    "\n",
    "This technical barrier prevents many people from effectively enhancing their photos, leading to either unedited images or reliance on one-size-fits-all filters that don't address the specific needs of each photo.\n",
    "\n",
    "## How Generative AI Solves This Problem\n",
    "\n",
    "Natural Language Processing (NLP) combined with computer vision creates a revolutionary approach to photo editing. Instead of manipulating technical controls, users can simply describe what they want in plain English:\n",
    "\n",
    "- \"Make the sunset colors more vibrant\"\n",
    "- \"Add more contrast and warmth to the portrait\"\n",
    "- \"Give this landscape a dramatic cinematic look\"\n",
    "- \"Fix the lighting in this dark indoor photo\"\n",
    "\n",
    "The AI system:\n",
    "1. **Interprets natural language** to understand the user's intent\n",
    "2. **Maps descriptions to technical operations** using function calling\n",
    "3. **Applies appropriate adjustments** to achieve the described effect\n",
    "4. **Provides transparency** by showing which operations were performed\n",
    "\n",
    "This notebook demonstrates how our Natural Language Photo Editor bridges the gap between human creative intent and technical execution, making photo editing accessible to everyone.\n"
   ],
   "id": "fcf68cf6d1850295"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment.\n"
   ],
   "id": "c4f6ef2670dd2723"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Import our photo editing package\n",
    "from photoedit_mvp import (\n",
    "    load_image, \n",
    "    save_image\n",
    ")\n",
    "\n",
    "# Import the natural language processor\n",
    "from photoedit_mvp.nl_processor import NLProcessor\n",
    "\n",
    "# Set up matplotlib for displaying images\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n"
   ],
   "id": "e5a091131989bf4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's define some helper functions to display images and results.\n"
   ],
   "id": "69c08c98a69cf066"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def display_image(image, title=None):\n",
    "    \"\"\"Display an image with an optional title.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if isinstance(image, str):\n",
    "        # If image is a file path, load it\n",
    "        image = load_image(image)\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        plt.title(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def display_before_after(before, after, titles=None):\n",
    "    \"\"\"Display before and after images side by side.\"\"\"\n",
    "    if titles is None:\n",
    "        titles = ['Before', 'After']\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    if isinstance(before, str):\n",
    "        before = load_image(before)\n",
    "    plt.imshow(before)\n",
    "    plt.axis('off')\n",
    "    plt.title(titles[0], fontsize=14)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    if isinstance(after, str):\n",
    "        after = load_image(after)\n",
    "    plt.imshow(after)\n",
    "    plt.axis('off')\n",
    "    plt.title(titles[1], fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_multiple(images, titles=None, cols=3):\n",
    "    \"\"\"Display multiple images in a grid.\"\"\"\n",
    "    n = len(images)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    \n",
    "    plt.figure(figsize=(5*cols, 5*rows))\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        if isinstance(image, str):\n",
    "            image = load_image(image)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        if titles and i < len(titles):\n",
    "            plt.title(titles[i], fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "3dacc90ab20b9446"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Understanding Natural Language Processing for Photo Editing\n",
    "\n",
    "Natural language processing for photo editing involves translating human descriptions into specific technical operations. This requires:\n",
    "\n",
    "1. **Understanding intent**: Parsing what the user wants to achieve\n",
    "2. **Parameter extraction**: Determining the magnitude and direction of adjustments\n",
    "3. **Function mapping**: Selecting the appropriate editing operations\n",
    "4. **Execution**: Applying the operations in the right sequence\n",
    "\n",
    "Let's implement the image processing functions that our natural language processor will use:\n"
   ],
   "id": "f9b5937752999ad0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def adjust_exposure(image, amount):\n",
    "    \"\"\"Adjust image exposure/brightness.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        amount: Adjustment amount (-1.0 to 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation for demonstration\n",
    "    result = image.copy().astype(float)\n",
    "    result = result * (1 + amount)\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "def adjust_contrast(image, multiplier):\n",
    "    \"\"\"Adjust image contrast.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        multiplier: Contrast multiplier (0.5 to 2.0)\n",
    "        \n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation for demonstration\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    result = image.copy().astype(float)\n",
    "    for i in range(3):\n",
    "        result[:,:,i] = (result[:,:,i] - mean[i]) * multiplier + mean[i]\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "def adjust_saturation(image, adjustment):\n",
    "    \"\"\"Adjust image saturation/vibrance.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        adjustment: Saturation adjustment (-1.0 to 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Convert to HSV, adjust S channel, convert back to RGB\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(float)\n",
    "    hsv[:,:,1] = hsv[:,:,1] * (1 + adjustment)\n",
    "    hsv[:,:,1] = np.clip(hsv[:,:,1], 0, 255)\n",
    "    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def adjust_temperature(image, adjustment):\n",
    "    \"\"\"Adjust image color temperature (warmth/coolness).\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        adjustment: Temperature adjustment (-0.5 to 0.5)\n",
    "        \n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation - increase red for warmth, blue for coolness\n",
    "    result = image.copy().astype(float)\n",
    "    if adjustment > 0:  # Warm\n",
    "        result[:,:,0] = np.clip(result[:,:,0] * (1 + adjustment), 0, 255)  # Red\n",
    "        result[:,:,2] = np.clip(result[:,:,2] * (1 - adjustment/2), 0, 255)  # Blue\n",
    "    else:  # Cool\n",
    "        result[:,:,2] = np.clip(result[:,:,2] * (1 - adjustment), 0, 255)  # Blue\n",
    "        result[:,:,0] = np.clip(result[:,:,0] * (1 + adjustment/2), 0, 255)  # Red\n",
    "    return result.astype(np.uint8)\n",
    "\n",
    "def adjust_sharpness(image, strength):\n",
    "    \"\"\"Adjust image sharpness.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        strength: Sharpness strength (0.0 to 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation using unsharp masking\n",
    "    blur = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    result = image.copy().astype(float)\n",
    "    result = result + strength * (image.astype(float) - blur)\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "def reduce_noise(image, strength):\n",
    "    \"\"\"Reduce noise in the image.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        strength: Noise reduction strength (0.0 to 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation using bilateral filter\n",
    "    # Adjust parameters based on strength\n",
    "    d = int(5 + strength * 10)  # Diameter of each pixel neighborhood\n",
    "    sigma_color = 50 + strength * 100  # Filter sigma in the color space\n",
    "    sigma_space = 50 + strength * 100  # Filter sigma in the coordinate space\n",
    "    \n",
    "    return cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n"
   ],
   "id": "b418c1b7f6d9f2ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Setting Up the Natural Language Processor\n",
    "\n",
    "Now let's set up our natural language processor and register the image processing functions we defined above. This will allow the processor to map natural language instructions to specific operations.\n"
   ],
   "id": "541909240bb85700"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the natural language processor\n",
    "nl_processor = NLProcessor()\n",
    "\n",
    "# Register our image processing functions\n",
    "nl_processor.register_function(\n",
    "    \"adjust_exposure\",\n",
    "    adjust_exposure,\n",
    "    \"Adjust the brightness/exposure of the image\",\n",
    "    {\"amount\": {\"type\": \"number\", \"description\": \"Amount to adjust exposure (-1.0 to 1.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_contrast\",\n",
    "    adjust_contrast,\n",
    "    \"Adjust the contrast of the image\",\n",
    "    {\"multiplier\": {\"type\": \"number\", \"description\": \"Contrast multiplier (0.5 to 2.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_saturation\",\n",
    "    adjust_saturation,\n",
    "    \"Adjust the color saturation/vibrance of the image\",\n",
    "    {\"adjustment\": {\"type\": \"number\", \"description\": \"Saturation adjustment (-1.0 to 1.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_temperature\",\n",
    "    adjust_temperature,\n",
    "    \"Adjust the color temperature (warmth/coolness) of the image\",\n",
    "    {\"adjustment\": {\"type\": \"number\", \"description\": \"Temperature adjustment (-0.5 to 0.5)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_sharpness\",\n",
    "    adjust_sharpness,\n",
    "    \"Adjust the sharpness/clarity of the image\",\n",
    "    {\"strength\": {\"type\": \"number\", \"description\": \"Sharpness strength (0.0 to 1.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"reduce_noise\",\n",
    "    reduce_noise,\n",
    "    \"Reduce noise/grain in the image\",\n",
    "    {\"strength\": {\"type\": \"number\", \"description\": \"Noise reduction strength (0.0 to 1.0)\"}}\n",
    ")\n"
   ],
   "id": "514e30a0ba869f42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Processing Natural Language Instructions\n",
    "\n",
    "Let's load a test image and try processing some natural language instructions.\n"
   ],
   "id": "f349e198830f71cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load a test image\n",
    "test_image_path = '../test_images/test_image.jpg'\n",
    "image = load_image(test_image_path)\n",
    "\n",
    "# Display the original image\n",
    "display_image(image, \"Original Image\")\n"
   ],
   "id": "c974e732fe47755e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's try some natural language instructions and see how the system interprets and applies them.\n",
   "id": "38ec039498c412a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define a function to process and display results\n",
    "def process_instruction(image, instruction):\n",
    "    \"\"\"Process a natural language instruction and display results.\"\"\"\n",
    "    print(f\"Instruction: '{instruction}'\")\n",
    "    \n",
    "    # Process the instruction\n",
    "    processed_image, metadata = nl_processor.process(image, instruction)\n",
    "    \n",
    "    # Display the functions that were called\n",
    "    print(\"\\nFunctions called:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "    \n",
    "    # Display before and after\n",
    "    display_before_after(image, processed_image, [\"Original Image\", f\"After: '{instruction}'\"])\n",
    "    \n",
    "    return processed_image\n",
    "\n",
    "# Try a simple instruction\n",
    "result1 = process_instruction(image, \"Make the image warmer and increase the contrast slightly\")\n"
   ],
   "id": "edb7bb86ab59d854"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's try some more complex instructions to see how the system handles them.\n",
   "id": "d7e68250a29b04c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Try more complex instructions\n",
    "instructions = [\n",
    "    \"Make the colors more vibrant and add some warmth\",\n",
    "    \"Increase contrast dramatically and make it cooler\",\n",
    "    \"Brighten the dark areas and add clarity\",\n",
    "    \"Give it a soft, dreamy look with reduced contrast\",\n",
    "    \"Sharpen the details and make colors pop\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for instruction in instructions:\n",
    "    print(f\"\\n{'='*50}\\n\")\n",
    "    result = process_instruction(image, instruction)\n",
    "    results.append(result)\n"
   ],
   "id": "9588292086b8fda8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Understanding How Instructions Are Parsed\n",
    "\n",
    "Let's take a closer look at how the natural language processor interprets different types of instructions. This will help us understand the relationship between language and editing operations.\n"
   ],
   "id": "f38186b79ad2d934"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define some instruction categories\n",
    "instruction_categories = {\n",
    "    \"Brightness/Exposure\": [\n",
    "        \"Brighten the image\",\n",
    "        \"Make the image darker\",\n",
    "        \"Increase exposure slightly\",\n",
    "        \"Fix the underexposed areas\"\n",
    "    ],\n",
    "    \"Color Temperature\": [\n",
    "        \"Make it warmer\",\n",
    "        \"Add a cool blue tone\",\n",
    "        \"Give it a warmer feel\",\n",
    "        \"Cool down the highlights\"\n",
    "    ],\n",
    "    \"Contrast\": [\n",
    "        \"Increase contrast\",\n",
    "        \"Make it more dramatic with higher contrast\",\n",
    "        \"Reduce contrast for a softer look\",\n",
    "        \"Add just a touch more contrast\"\n",
    "    ],\n",
    "    \"Saturation/Vibrance\": [\n",
    "        \"Make colors more vibrant\",\n",
    "        \"Increase saturation\",\n",
    "        \"Tone down the colors\",\n",
    "        \"Make it slightly less saturated\"\n",
    "    ],\n",
    "    \"Clarity/Sharpness\": [\n",
    "        \"Sharpen the details\",\n",
    "        \"Add more clarity\",\n",
    "        \"Make it slightly softer\",\n",
    "        \"Enhance the fine details\"\n",
    "    ],\n",
    "    \"Noise Reduction\": [\n",
    "        \"Reduce the noise\",\n",
    "        \"Remove grain\",\n",
    "        \"Smooth out the noisy areas\",\n",
    "        \"Clean up the image\"\n",
    "    ],\n",
    "    \"Combined Effects\": [\n",
    "        \"Make it warmer and increase contrast\",\n",
    "        \"Brighten and add clarity\",\n",
    "        \"Cool it down and make colors pop\",\n",
    "        \"Give it a vintage look with warm tones and reduced contrast\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Let's analyze how each category of instructions is interpreted\n",
    "for category, instructions_list in instruction_categories.items():\n",
    "    print(f\"\\n{'='*80}\\n{category} Instructions\\n{'='*80}\")\n",
    "    \n",
    "    for instruction in instructions_list:\n",
    "        print(f\"\\nInstruction: '{instruction}'\")\n",
    "        \n",
    "        # Process the instruction but don't apply it (just analyze)\n",
    "        _, metadata = nl_processor.process(image, instruction)\n",
    "        \n",
    "        # Display the functions that would be called\n",
    "        print(\"Functions that would be called:\")\n",
    "        for func_call in metadata['functions_called']:\n",
    "            print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "        \n",
    "        print(\"-\" * 50)\n"
   ],
   "id": "e5530cbd94d6ba46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Innovative Use Case: Guided Photo Editing Through Conversation\n",
    "\n",
    "One of the most powerful applications of natural language photo editing is the ability to guide users through an iterative editing process, similar to working with a professional photo editor. Let's demonstrate this conversational editing workflow:\n"
   ],
   "id": "c8e81c1b8f6cc9a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def conversational_editing_workflow(image):\n",
    "    \"\"\"Demonstrate a conversational editing workflow.\"\"\"\n",
    "    print(\"=== Conversational Photo Editing Workflow ===\\n\")\n",
    "    print(\"Starting with the original image:\")\n",
    "    display_image(image, \"Original Image\")\n",
    "    \n",
    "    # Step 1: Initial assessment and basic enhancement\n",
    "    print(\"\\nStep 1: Initial assessment and basic enhancement\")\n",
    "    print(\"User: \\\"Enhance this photo to make it look better overall\\\"\")\n",
    "    \n",
    "    current_image, metadata = nl_processor.process(image, \"Enhance this photo to make it look better overall\")\n",
    "    \n",
    "    print(\"\\nAI: \\\"I've made some basic enhancements. I've slightly increased the exposure, added a bit of contrast, and made the colors more vibrant. Here's the result:\\\"\")\n",
    "    print(\"\\nOperations performed:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "    \n",
    "    display_image(current_image, \"After Basic Enhancement\")\n",
    "    \n",
    "    # Step 2: Specific adjustment based on user feedback\n",
    "    print(\"\\nStep 2: Specific adjustment based on user feedback\")\n",
    "    print(\"User: \\\"It looks better, but I'd like it to be a bit warmer and more dramatic\\\"\")\n",
    "    \n",
    "    previous_image = current_image.copy()\n",
    "    current_image, metadata = nl_processor.process(current_image, \"Make it warmer and more dramatic\")\n",
    "    \n",
    "    print(\"\\nAI: \\\"I've added warmth by adjusting the color temperature and increased the contrast for a more dramatic look. Here's the updated image:\\\"\")\n",
    "    print(\"\\nOperations performed:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "    \n",
    "    display_before_after(previous_image, current_image, [\"After Basic Enhancement\", \"Warmer and More Dramatic\"])\n",
    "    \n",
    "    # Step 3: Fine-tuning\n",
    "    print(\"\\nStep 3: Fine-tuning\")\n",
    "    print(\"User: \\\"That's closer to what I want, but now the colors are a bit too intense. Can you tone down the saturation slightly but keep the contrast?\\\"\")\n",
    "    \n",
    "    previous_image = current_image.copy()\n",
    "    current_image, metadata = nl_processor.process(current_image, \"Reduce saturation slightly but maintain contrast\")\n",
    "    \n",
    "    print(\"\\nAI: \\\"I've reduced the color saturation while maintaining the contrast levels. Here's the result:\\\"\")\n",
    "    print(\"\\nOperations performed:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "    \n",
    "    display_before_after(previous_image, current_image, [\"Warmer and More Dramatic\", \"Fine-tuned\"])\n",
    "    \n",
    "    # Step 4: Final touches\n",
    "    print(\"\\nStep 4: Final touches\")\n",
    "    print(\"User: \\\"That's looking good! As a final touch, can you sharpen it a bit to bring out the details?\\\"\")\n",
    "    \n",
    "    previous_image = current_image.copy()\n",
    "    current_image, metadata = nl_processor.process(current_image, \"Sharpen to bring out details\")\n",
    "    \n",
    "    print(\"\\nAI: \\\"I've applied sharpening to enhance the details. Here's your final image:\\\"\")\n",
    "    print(\"\\nOperations performed:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "    \n",
    "    display_before_after(previous_image, current_image, [\"Fine-tuned\", \"Final Image\"])\n",
    "    \n",
    "    # Show the complete transformation\n",
    "    print(\"\\nComplete Transformation:\")\n",
    "    display_before_after(image, current_image, [\"Original Image\", \"Final Edited Image\"])\n",
    "    \n",
    "    return current_image\n",
    "\n",
    "# Run the conversational editing workflow\n",
    "final_image = conversational_editing_workflow(image)\n"
   ],
   "id": "9024efbc0f6ebc73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Comparing Natural Language Editing to Traditional Methods\n",
    "\n",
    "Let's compare the natural language approach to traditional editing methods to highlight the advantages of using AI.\n"
   ],
   "id": "d414eec773be00f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compare_approaches():\n",
    "    \"\"\"Compare traditional editing vs. natural language editing.\"\"\"\n",
    "    print(\"=== Traditional Editing vs. Natural Language Editing ===\\n\")\n",
    "    \n",
    "    # Define a set of traditional editing steps\n",
    "    traditional_steps = [\n",
    "        {\"operation\": \"Adjust exposure\", \"value\": 0.2, \"function\": adjust_exposure, \"args\": {\"amount\": 0.2}},\n",
    "        {\"operation\": \"Increase contrast\", \"value\": 1.2, \"function\": adjust_contrast, \"args\": {\"multiplier\": 1.2}},\n",
    "        {\"operation\": \"Add warmth\", \"value\": 0.15, \"function\": adjust_temperature, \"args\": {\"adjustment\": 0.15}},\n",
    "        {\"operation\": \"Increase saturation\", \"value\": 0.1, \"function\": adjust_saturation, \"args\": {\"adjustment\": 0.1}},\n",
    "        {\"operation\": \"Sharpen\", \"value\": 0.3, \"function\": adjust_sharpness, \"args\": {\"strength\": 0.3}}\n",
    "    ]\n",
    "    \n",
    "    # Define equivalent natural language instructions\n",
    "    nl_instructions = [\n",
    "        \"Brighten the image slightly\",\n",
    "        \"Add a bit more contrast\",\n",
    "        \"Make it slightly warmer\",\n",
    "        \"Make the colors a bit more vibrant\",\n",
    "        \"Sharpen the details\"\n",
    "    ]\n",
    "    \n",
    "    # Apply traditional editing steps\n",
    "    traditional_result = image.copy()\n",
    "    print(\"Traditional Editing Approach:\")\n",
    "    print(\"1. User needs to know which technical adjustments to make\")\n",
    "    print(\"2. User must understand what each control does\")\n",
    "    print(\"3. User must determine appropriate values for each adjustment\")\n",
    "    print(\"\\nTraditional Editing Steps:\")\n",
    "    \n",
    "    for step in traditional_steps:\n",
    "        print(f\"- {step['operation']}: {step['value']}\")\n",
    "        traditional_result = step[\"function\"](traditional_result, **step[\"args\"])\n",
    "    \n",
    "    # Apply natural language editing\n",
    "    nl_result = image.copy()\n",
    "    print(\"\\nNatural Language Editing Approach:\")\n",
    "    print(\"1. User simply describes the desired changes in plain English\")\n",
    "    print(\"2. AI interprets instructions and applies appropriate adjustments\")\n",
    "    print(\"3. User can refine results with additional natural language feedback\")\n",
    "    print(\"\\nNatural Language Instructions:\")\n",
    "    \n",
    "    for instruction in nl_instructions:\n",
    "        print(f\"- \\\"{instruction}\\\"\")\n",
    "        nl_result, _ = nl_processor.process(nl_result, instruction)\n",
    "    \n",
    "    # Display the results side by side\n",
    "    print(\"\\nComparison of Results:\")\n",
    "    display_multiple([image, traditional_result, nl_result], \n",
    "                    [\"Original Image\", \"Traditional Editing Result\", \"Natural Language Editing Result\"])\n",
    "    \n",
    "    print(\"\\nKey Advantages of Natural Language Editing:\")\n",
    "    print(\"1. Accessibility: No technical knowledge required\")\n",
    "    print(\"2. Efficiency: Faster editing with fewer steps\")\n",
    "    print(\"3. Intuitiveness: Edit using familiar language instead of technical controls\")\n",
    "    print(\"4. Flexibility: Can handle complex combined operations with a single instruction\")\n",
    "    print(\"5. Learnability: Easier for beginners to get started with photo editing\")\n",
    "\n",
    "# Run the comparison\n",
    "compare_approaches()\n"
   ],
   "id": "f809e77a10f1282b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Natural language photo editing represents a significant advancement in making creative tools more accessible and intuitive. By bridging the gap between human intent and technical execution, this approach:\n",
    "\n",
    "1. **Democratizes photo editing** by removing technical barriers\n",
    "2. **Accelerates the editing workflow** by reducing the number of steps required\n",
    "3. **Makes editing more intuitive** by allowing users to express their creative vision directly\n",
    "4. **Provides educational value** by showing which technical operations correspond to natural language descriptions\n",
    "5. **Enables iterative refinement** through conversational interaction\n",
    "\n",
    "The future of creative software lies in these natural language interfaces that focus on what users want to achieve rather than how to achieve it. This shift from technical controls to intent-based editing will continue to expand as AI models become more sophisticated in understanding both language and visual aesthetics.\n",
    "\n",
    "As demonstrated in this notebook, the combination of natural language processing and computer vision creates a powerful new paradigm for photo editing that makes professional-quality results accessible to everyone, regardless of their technical expertise."
   ],
   "id": "1d4951aa205baab9"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
