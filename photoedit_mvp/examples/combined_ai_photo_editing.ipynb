{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AI-Powered Photo Editing: Comprehensive Guide to Intelligent Image Enhancement\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook combines three key aspects of our AI-powered photo editing system:\n",
    "\n",
    "1. **AI-Powered Image Analysis**: Automatically analyzing image content and recommending adjustments\n",
    "2. **Natural Language Photo Editing**: Editing photos using plain English instructions\n",
    "3. **RAG-Based Style Recommendations**: Suggesting cinematic styles based on image content\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Photo editing traditionally requires significant technical knowledge and artistic skill. Users need to understand complex concepts like exposure, contrast, color balance, and composition to achieve professional-looking results. This creates a high barrier to entry for casual photographers who want to enhance their images but lack the technical expertise.\n",
    "\n",
    "Additionally, the editing process can be time-consuming, requiring multiple adjustments and trial-and-error to achieve the desired look. This is especially challenging when dealing with different types of images (landscapes, portraits, low-light scenes) that each require specialized editing approaches.\n",
    "\n",
    "Traditional photo editing interfaces rely on technical sliders, complex terminology, and specialized knowledge that can be intimidating for casual users. Even with simplified consumer apps, users must:\n",
    "\n",
    "1. Understand what each control does (exposure, contrast, saturation, etc.)\n",
    "2. Know which adjustments to make for specific visual goals\n",
    "3. Make multiple trial-and-error attempts to achieve desired results\n",
    "4. Remember which combinations of settings create specific looks\n",
    "\n",
    "Creating professional-looking, cinematic styles for photos traditionally requires:\n",
    "\n",
    "1. **Extensive knowledge of cinematography** and color grading techniques\n",
    "2. **Understanding of visual aesthetics** from different film genres and directors\n",
    "3. **Technical expertise** in complex editing software\n",
    "4. **Time-consuming experimentation** to achieve desired looks\n",
    "\n",
    "## How Generative AI Solves These Problems\n",
    "\n",
    "Generative AI transforms the photo editing experience by bringing intelligence and automation to the process. Instead of requiring users to understand technical details, AI can:\n",
    "\n",
    "1. **Analyze image content** to understand what's in the photo (people, landscapes, objects)\n",
    "2. **Assess technical qualities** like lighting conditions, color balance, and exposure\n",
    "3. **Recommend appropriate adjustments** based on the specific content and conditions\n",
    "4. **Understand natural language instructions** from users who can describe what they want in plain English\n",
    "5. **Suggest cinematic styles** that match the image content using knowledge of cinematography techniques\n",
    "\n",
    "Natural Language Processing (NLP) combined with computer vision creates a revolutionary approach to photo editing. Instead of manipulating technical controls, users can simply describe what they want in plain English:\n",
    "\n",
    "- \"Make the sunset colors more vibrant\"\n",
    "- \"Add more contrast and warmth to the portrait\"\n",
    "- \"Give this landscape a dramatic cinematic look\"\n",
    "- \"Fix the lighting in this dark indoor photo\"\n",
    "\n",
    "Retrieval Augmented Generation (RAG) combined with computer vision creates an intelligent style recommendation system that:\n",
    "\n",
    "1. **Analyzes image content** to understand the scene type, lighting conditions, and subjects\n",
    "2. **Retrieves knowledge** about cinematography techniques and styles from a curated database\n",
    "3. **Matches content to appropriate styles** based on cinematography principles\n",
    "4. **Explains recommendations** with clear reasoning about why each style works for the image\n",
    "5. **Allows natural language queries** so users can describe the look they want to achieve\n",
    "\n",
    "This notebook demonstrates how our AI Photo Editor uses these capabilities to make professional-quality editing accessible to everyone, regardless of technical expertise.\n"
   ],
   "id": "51e766476971bf62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment.\n"
   ],
   "id": "5cab107d73c37ed5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Import our photo editing package\n",
    "from photoedit_mvp import (\n",
    "    load_image, \n",
    "    save_image, \n",
    "    analyze_image, \n",
    "    apply_adjustments\n",
    ")\n",
    "\n",
    "# Import AI-specific modules\n",
    "from photoedit_mvp.ai_analyzer import AIImageAnalyzer\n",
    "from photoedit_mvp.nl_processor import NLProcessor\n",
    "from photoedit_mvp.rag_style_engine import RAGStyleEngine\n",
    "\n",
    "# Set up matplotlib for displaying images\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n"
   ],
   "id": "bea5d89a1d8e0a76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's define some helper functions to display images and results.\n"
   ],
   "id": "a446df7d7be1dd53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def display_image(image, title=None):\n",
    "    \"\"\"Display an image with an optional title.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if isinstance(image, str):\n",
    "        # If image is a file path, load it\n",
    "        image = load_image(image)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        plt.title(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def display_before_after(before, after, titles=None):\n",
    "    \"\"\"Display before and after images side by side.\"\"\"\n",
    "    if titles is None:\n",
    "        titles = ['Before', 'After']\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if isinstance(before, str):\n",
    "        before = load_image(before)\n",
    "    plt.imshow(before)\n",
    "    plt.axis('off')\n",
    "    plt.title(titles[0], fontsize=14)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if isinstance(after, str):\n",
    "        after = load_image(after)\n",
    "    plt.imshow(after)\n",
    "    plt.axis('off')\n",
    "    plt.title(titles[1], fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_multiple(images, titles=None, cols=3):\n",
    "    \"\"\"Display multiple images in a grid.\"\"\"\n",
    "    n = len(images)\n",
    "    rows = (n + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=(5*cols, 5*rows))\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        if isinstance(image, str):\n",
    "            image = load_image(image)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        if titles and i < len(titles):\n",
    "            plt.title(titles[i], fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "aadae7799c7ebe47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Test Image\n",
    "\n",
    "Let's load a test image that we'll use throughout this notebook.\n"
   ],
   "id": "2ea7867bc1684f40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load a test image\n",
    "test_image_path = '../test_images/test_image.jpg'\n",
    "image = load_image(test_image_path)\n",
    "\n",
    "# Display the image\n",
    "display_image(image, \"Test Image\")\n"
   ],
   "id": "ef4089e519306e7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Part 1: AI-Powered Image Analysis\n",
    "\n",
    "One of the key innovations in our photo editor is the ability to analyze image content using AI. This allows the application to understand what's in the photo and make intelligent recommendations based on the content.\n"
   ],
   "id": "ce54861e9f633a15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the AI image analyzer\n",
    "ai_analyzer = AIImageAnalyzer()\n",
    "\n",
    "# Analyze the image\n",
    "adjustments, analysis = ai_analyzer.analyze(image)\n",
    "\n",
    "# Display the analysis results\n",
    "print(\"AI Image Analysis Results:\")\n",
    "print(f\"Scene Type: {analysis['scene_type']}\")\n",
    "print(f\"Lighting Condition: {analysis['lighting_condition']}\")\n",
    "print(f\"Faces Detected: {analysis['face_count']}\")\n",
    "print(\"\\nDetected Objects:\")\n",
    "for obj in analysis['objects']:\n",
    "    print(f\"- {obj['class']} (confidence: {obj['confidence']:.2f})\")\n",
    "\n",
    "print(\"\\nDominant Colors:\")\n",
    "for i, color in enumerate(analysis['color_palette'][:3]):\n",
    "    print(f\"- Color {i+1}: RGB{tuple(color)}\")\n",
    "\n",
    "print(\"\\nRecommended Adjustments:\")\n",
    "for adj in adjustments:\n",
    "    print(f\"- {adj.parameter}: {adj.suggested} {adj.unit} - {adj.description}\")\n"
   ],
   "id": "5a2d83cc65a539"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing the AI Analysis\n",
    "\n",
    "Let's visualize some of the analysis results to better understand what the AI is seeing.\n"
   ],
   "id": "b450b2cc5409a99a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize the color palette\n",
    "def display_color_palette(colors):\n",
    "    \"\"\"Display the color palette as color swatches.\"\"\"\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i, color in enumerate(colors):\n",
    "        plt.subplot(1, len(colors), i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow([[color]])\n",
    "        plt.title(f\"RGB{tuple(color)}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Dominant Color Palette:\")\n",
    "display_color_palette(analysis['color_palette'][:5])\n"
   ],
   "id": "a9c825f5570ce059"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Applying AI-Recommended Adjustments\n",
    "\n",
    "Now that we have AI-recommended adjustments, let's apply them to the image and see the results.\n"
   ],
   "id": "b2eeb8e5f12cc8f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply the recommended adjustments\n",
    "adjusted_image = apply_adjustments(image, adjustments)\n",
    "\n",
    "# Display before and after\n",
    "display_before_after(image, adjusted_image, [\"Original Image\", \"AI-Enhanced Image\"])\n"
   ],
   "id": "be3ed99458e9b789"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Part 2: Natural Language Photo Editing\n",
    "\n",
    "Another innovative feature of our photo editor is the ability to edit photos using natural language instructions. This allows users to describe what they want in plain English, without needing to understand technical terms or complex editing tools.\n",
    "\n",
    "## Image Processing Functions\n",
    "\n",
    "Let's implement the image processing functions that our natural language processor will use:\n"
   ],
   "id": "15893e292fc2030d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def adjust_exposure(image, amount):\n",
    "    \"\"\"Adjust image exposure/brightness.\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        amount: Adjustment amount (-1.0 to 1.0)\n",
    "\n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation for demonstration\n",
    "    result = image.copy().astype(float)\n",
    "    result = result * (1 + amount)\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "def adjust_contrast(image, multiplier):\n",
    "    \"\"\"Adjust image contrast.\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        multiplier: Contrast multiplier (0.5 to 2.0)\n",
    "\n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation for demonstration\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    result = image.copy().astype(float)\n",
    "    for i in range(3):\n",
    "        result[:,:,i] = (result[:,:,i] - mean[i]) * multiplier + mean[i]\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "def adjust_saturation(image, adjustment):\n",
    "    \"\"\"Adjust image saturation/vibrance.\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        adjustment: Saturation adjustment (-1.0 to 1.0)\n",
    "\n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Convert to HSV, adjust S channel, convert back to RGB\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(float)\n",
    "    hsv[:,:,1] = hsv[:,:,1] * (1 + adjustment)\n",
    "    hsv[:,:,1] = np.clip(hsv[:,:,1], 0, 255)\n",
    "    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def adjust_temperature(image, adjustment):\n",
    "    \"\"\"Adjust image color temperature (warmth/coolness).\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        adjustment: Temperature adjustment (-0.5 to 0.5)\n",
    "\n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation - increase red for warmth, blue for coolness\n",
    "    result = image.copy().astype(float)\n",
    "    if adjustment > 0:  # Warm\n",
    "        result[:,:,0] = np.clip(result[:,:,0] * (1 + adjustment), 0, 255)  # Red\n",
    "        result[:,:,2] = np.clip(result[:,:,2] * (1 - adjustment/2), 0, 255)  # Blue\n",
    "    else:  # Cool\n",
    "        result[:,:,2] = np.clip(result[:,:,2] * (1 - adjustment), 0, 255)  # Blue\n",
    "        result[:,:,0] = np.clip(result[:,:,0] * (1 + adjustment/2), 0, 255)  # Red\n",
    "    return result.astype(np.uint8)\n",
    "\n",
    "def adjust_sharpness(image, strength):\n",
    "    \"\"\"Adjust image sharpness.\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        strength: Sharpness strength (0.0 to 1.0)\n",
    "\n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation using unsharp masking\n",
    "    blur = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    result = image.copy().astype(float)\n",
    "    result = result + strength * (image.astype(float) - blur)\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "def reduce_noise(image, strength):\n",
    "    \"\"\"Reduce noise in the image.\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        strength: Noise reduction strength (0.0 to 1.0)\n",
    "\n",
    "    Returns:\n",
    "        Adjusted image\n",
    "    \"\"\"\n",
    "    # Simple implementation using bilateral filter\n",
    "    # Adjust parameters based on strength\n",
    "    d = int(5 + strength * 10)  # Diameter of each pixel neighborhood\n",
    "    sigma_color = 50 + strength * 100  # Filter sigma in the color space\n",
    "    sigma_space = 50 + strength * 100  # Filter sigma in the coordinate space\n",
    "\n",
    "    return cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n"
   ],
   "id": "1e7140e66022bd00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting Up the Natural Language Processor\n",
    "\n",
    "Now let's set up our natural language processor and register the image processing functions we defined above. This will allow the processor to map natural language instructions to specific operations.\n"
   ],
   "id": "6a756c178c9a6393"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the natural language processor\n",
    "nl_processor = NLProcessor()\n",
    "\n",
    "# Register our image processing functions\n",
    "nl_processor.register_function(\n",
    "    \"adjust_exposure\",\n",
    "    adjust_exposure,\n",
    "    \"Adjust the brightness/exposure of the image\",\n",
    "    {\"amount\": {\"type\": \"number\", \"description\": \"Amount to adjust exposure (-1.0 to 1.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_contrast\",\n",
    "    adjust_contrast,\n",
    "    \"Adjust the contrast of the image\",\n",
    "    {\"multiplier\": {\"type\": \"number\", \"description\": \"Contrast multiplier (0.5 to 2.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_saturation\",\n",
    "    adjust_saturation,\n",
    "    \"Adjust the color saturation/vibrance of the image\",\n",
    "    {\"adjustment\": {\"type\": \"number\", \"description\": \"Saturation adjustment (-1.0 to 1.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_temperature\",\n",
    "    adjust_temperature,\n",
    "    \"Adjust the color temperature (warmth/coolness) of the image\",\n",
    "    {\"adjustment\": {\"type\": \"number\", \"description\": \"Temperature adjustment (-0.5 to 0.5)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"adjust_sharpness\",\n",
    "    adjust_sharpness,\n",
    "    \"Adjust the sharpness/clarity of the image\",\n",
    "    {\"strength\": {\"type\": \"number\", \"description\": \"Sharpness strength (0.0 to 1.0)\"}}\n",
    ")\n",
    "\n",
    "nl_processor.register_function(\n",
    "    \"reduce_noise\",\n",
    "    reduce_noise,\n",
    "    \"Reduce noise/grain in the image\",\n",
    "    {\"strength\": {\"type\": \"number\", \"description\": \"Noise reduction strength (0.0 to 1.0)\"}}\n",
    ")\n"
   ],
   "id": "948d7e642c448c51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Processing Natural Language Instructions\n",
    "\n",
    "Let's try some natural language instructions and see how the system interprets and applies them.\n"
   ],
   "id": "b72077004c3eebee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define a function to process and display results\n",
    "def process_instruction(image, instruction):\n",
    "    \"\"\"Process a natural language instruction and display results.\"\"\"\n",
    "    print(f\"Instruction: '{instruction}'\")\n",
    "\n",
    "    # Process the instruction\n",
    "    processed_image, metadata = nl_processor.process(image, instruction)\n",
    "\n",
    "    # Display the functions that were called\n",
    "    print(\"\\nFunctions called:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "\n",
    "    # Display before and after\n",
    "    display_before_after(image, processed_image, [\"Original Image\", f\"After: '{instruction}'\"])\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "# Try a simple instruction\n",
    "result1 = process_instruction(image, \"Make the image warmer and increase the contrast slightly\")\n"
   ],
   "id": "d3a22141fd5723a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's try some more complex instructions to see how the system handles them.\n",
   "id": "ed2b2b857ba9b4a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Try more complex instructions\n",
    "instructions = [\n",
    "    \"Make the colors more vibrant and add some warmth\",\n",
    "    \"Increase contrast dramatically and make it cooler\",\n",
    "    \"Brighten the dark areas and add clarity\",\n",
    "    \"Give it a soft, dreamy look with reduced contrast\",\n",
    "    \"Sharpen the details and make colors pop\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for instruction in instructions:\n",
    "    print(f\"\\n{'='*50}\\n\")\n",
    "    result = process_instruction(image, instruction)\n",
    "    results.append(result)\n"
   ],
   "id": "1086fd6dec2ff158"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conversational Editing Workflow\n",
    "\n",
    "One of the most powerful applications of natural language photo editing is the ability to guide users through an iterative editing process, similar to working with a professional photo editor. Let's demonstrate this conversational editing workflow:\n"
   ],
   "id": "f624ef4ab932aecb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def conversational_editing_workflow(image):\n",
    "    \"\"\"Demonstrate a conversational editing workflow.\"\"\"\n",
    "    print(\"=== Conversational Photo Editing Workflow ===\\n\")\n",
    "    print(\"Starting with the original image:\")\n",
    "    display_image(image, \"Original Image\")\n",
    "\n",
    "    # Step 1: Initial assessment and basic enhancement\n",
    "    print(\"\\nStep 1: Initial assessment and basic enhancement\")\n",
    "    print(\"User: \\\"Enhance this photo to make it look better overall\\\"\")\n",
    "\n",
    "    current_image, metadata = nl_processor.process(image, \"Enhance this photo to make it look better overall\")\n",
    "\n",
    "    print(\"\\nAI: \\\"I've made some basic enhancements. I've slightly increased the exposure, added a bit of contrast, and made the colors more vibrant. Here's the result:\\\"\")\n",
    "    print(\"\\nOperations performed:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "\n",
    "    display_image(current_image, \"After Basic Enhancement\")\n",
    "\n",
    "    # Step 2: Specific adjustment based on user feedback\n",
    "    print(\"\\nStep 2: Specific adjustment based on user feedback\")\n",
    "    print(\"User: \\\"It looks better, but I'd like it to be a bit warmer and more dramatic\\\"\")\n",
    "\n",
    "    previous_image = current_image.copy()\n",
    "    current_image, metadata = nl_processor.process(current_image, \"Make it warmer and more dramatic\")\n",
    "\n",
    "    print(\"\\nAI: \\\"I've added warmth by adjusting the color temperature and increased the contrast for a more dramatic look. Here's the updated image:\\\"\")\n",
    "    print(\"\\nOperations performed:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "\n",
    "    display_before_after(previous_image, current_image, [\"After Basic Enhancement\", \"Warmer and More Dramatic\"])\n",
    "\n",
    "    # Step 3: Fine-tuning\n",
    "    print(\"\\nStep 3: Fine-tuning\")\n",
    "    print(\"User: \\\"That's closer to what I want, but now the colors are a bit too intense. Can you tone down the saturation slightly but keep the contrast?\\\"\")\n",
    "\n",
    "    previous_image = current_image.copy()\n",
    "    current_image, metadata = nl_processor.process(current_image, \"Reduce saturation slightly but maintain contrast\")\n",
    "\n",
    "    print(\"\\nAI: \\\"I've reduced the color saturation while maintaining the contrast levels. Here's the result:\\\"\")\n",
    "    print(\"\\nOperations performed:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "\n",
    "    display_before_after(previous_image, current_image, [\"Warmer and More Dramatic\", \"Fine-tuned\"])\n",
    "\n",
    "    # Step 4: Final touches\n",
    "    print(\"\\nStep 4: Final touches\")\n",
    "    print(\"User: \\\"That's looking good! As a final touch, can you sharpen it a bit to bring out the details?\\\"\")\n",
    "\n",
    "    previous_image = current_image.copy()\n",
    "    current_image, metadata = nl_processor.process(current_image, \"Sharpen to bring out details\")\n",
    "\n",
    "    print(\"\\nAI: \\\"I've applied sharpening to enhance the details. Here's your final image:\\\"\")\n",
    "    print(\"\\nOperations performed:\")\n",
    "    for func_call in metadata['functions_called']:\n",
    "        print(f\"- {func_call['name']}({', '.join([f'{k}={v}' for k, v in func_call['args'].items()])})\")\n",
    "\n",
    "    display_before_after(previous_image, current_image, [\"Fine-tuned\", \"Final Image\"])\n",
    "\n",
    "    # Show the complete transformation\n",
    "    print(\"\\nComplete Transformation:\")\n",
    "    display_before_after(image, current_image, [\"Original Image\", \"Final Edited Image\"])\n",
    "\n",
    "    return current_image\n",
    "\n",
    "# Run the conversational editing workflow\n",
    "final_image = conversational_editing_workflow(image)\n"
   ],
   "id": "ceb15dcf9e3df1c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Part 3: RAG-Based Style Recommendations\n",
    "\n",
    "Our photo editor also uses Retrieval Augmented Generation (RAG) to recommend cinematic styles based on image content. This combines a knowledge base of cinematography techniques with AI image analysis to suggest styles that match the content of the photo.\n",
    "\n",
    "## Understanding Retrieval Augmented Generation (RAG) for Style Recommendations\n",
    "\n",
    "Retrieval Augmented Generation (RAG) is a powerful AI technique that combines the strengths of retrieval-based systems with generative models. In our photo editing application, RAG works by:\n",
    "\n",
    "1. **Retrieving relevant information** from a knowledge base of cinematography styles and techniques\n",
    "2. **Augmenting the recommendation process** with this retrieved knowledge\n",
    "3. **Generating style recommendations** that are tailored to the specific image content\n",
    "\n",
    "This approach has several advantages over traditional preset filters:\n",
    "\n",
    "- **Content-aware recommendations**: Styles are suggested based on what's in the photo\n",
    "- **Educational value**: Users learn about cinematography techniques and why they work\n",
    "- **Flexibility**: The system can adapt to both image content and user descriptions\n",
    "- **Transparency**: Clear explanations for why each style is recommended\n"
   ],
   "id": "ce5d60fafd3ecfaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the RAG style engine\n",
    "rag_engine = RAGStyleEngine()\n",
    "\n",
    "# Get style recommendations based on image content\n",
    "recommendations = rag_engine.recommend_style(image)\n",
    "\n",
    "# Display the recommendations\n",
    "print(\"Style Recommendations Based on Image Content:\")\n",
    "for i, rec in enumerate(recommendations):\n",
    "    print(f\"\\n{i+1}. {rec['style']} (Score: {rec['score']})\")\n",
    "    print(f\"   Description: {rec['description']}\")\n",
    "    print(f\"   Reasoning:\")\n",
    "    for reason in rec['reasoning']:\n",
    "        print(f\"   - {reason}\")\n"
   ],
   "id": "66216be08d0a5caf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's apply these recommended styles to our image and see the results.\n",
   "id": "440fc1a3cc5a3c2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply the recommended styles\n",
    "styled_images = []\n",
    "style_names = []\n",
    "\n",
    "for rec in recommendations:\n",
    "    style_name = rec['style']\n",
    "    styled = rag_engine.apply_style(image, style_name)\n",
    "    styled_images.append(styled)\n",
    "    style_names.append(style_name)\n",
    "\n",
    "# Display the original and styled images\n",
    "display_multiple([image] + styled_images, [\"Original\"] + style_names)\n"
   ],
   "id": "f868426a44d2447d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Style Recommendations Based on Description\n",
    "\n",
    "We can also recommend styles based on a description provided by the user. This allows users to describe the look they want in natural language, and the system will find matching styles.\n"
   ],
   "id": "822d6bf4620eda5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get style recommendations based on a description\n",
    "description = \"I want a dramatic movie look with high contrast\"\n",
    "desc_recommendations = rag_engine.recommend_style(image, description)\n",
    "\n",
    "# Display the recommendations\n",
    "print(f\"Style Recommendations Based on Description: '{description}'\")\n",
    "for i, rec in enumerate(desc_recommendations):\n",
    "    print(f\"\\n{i+1}. {rec['style']} (Score: {rec['score']})\")\n",
    "    print(f\"   Description: {rec['description']}\")\n",
    "    print(f\"   Reasoning:\")\n",
    "    for reason in rec['reasoning']:\n",
    "        print(f\"   - {reason}\")\n"
   ],
   "id": "6b59c68fa5d3adf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's apply these description-based style recommendations.\n",
   "id": "8a7ce10f2b303057"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply the description-based recommended styles\n",
    "desc_styled_images = []\n",
    "desc_style_names = []\n",
    "\n",
    "for rec in desc_recommendations:\n",
    "    style_name = rec['style']\n",
    "    styled = rag_engine.apply_style(image, style_name)\n",
    "    desc_styled_images.append(styled)\n",
    "    desc_style_names.append(style_name)\n",
    "\n",
    "# Display the original and styled images\n",
    "display_multiple([image] + desc_styled_images, [\"Original\"] + desc_style_names)\n"
   ],
   "id": "f1dd1807bf53592d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Style-Based Storytelling\n",
    "\n",
    "One of the most powerful applications of RAG-based style recommendations is helping users tell visual stories through consistent styling. Different scenes in a story might require different cinematic looks to convey the right mood and atmosphere.\n"
   ],
   "id": "a736648b58d9b3fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def style_based_storytelling():\n",
    "    \"\"\"Demonstrate style-based storytelling with RAG recommendations.\"\"\"\n",
    "    print(\"=== Style-Based Storytelling ===\\n\")\n",
    "    print(\"Imagine you're creating a visual story with different scenes. Each scene needs a different mood and atmosphere.\")\n",
    "\n",
    "    # Define our story scenes\n",
    "    story_scenes = [\n",
    "        {\n",
    "            \"scene_name\": \"Opening Scene - Mysterious Beginning\",\n",
    "            \"description\": \"The story begins with a mysterious, moody atmosphere\",\n",
    "            \"style_query\": \"mysterious dark moody atmosphere like a thriller\"\n",
    "        },\n",
    "        {\n",
    "            \"scene_name\": \"Flashback Scene - Nostalgic Past\",\n",
    "            \"description\": \"We flash back to happier times in the past\",\n",
    "            \"style_query\": \"warm nostalgic vintage look\"\n",
    "        },\n",
    "        {\n",
    "            \"scene_name\": \"Action Scene - Dramatic Confrontation\",\n",
    "            \"description\": \"The protagonist faces a dramatic confrontation\",\n",
    "            \"style_query\": \"dramatic high contrast action movie style\"\n",
    "        },\n",
    "        {\n",
    "            \"scene_name\": \"Resolution Scene - Hopeful Ending\",\n",
    "            \"description\": \"The story resolves with a hopeful, uplifting ending\",\n",
    "            \"style_query\": \"bright vibrant hopeful cinematic\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Process each scene\n",
    "    for scene in story_scenes:\n",
    "        print(f\"\\n{'='*80}\\n{scene['scene_name']}\\n{'='*80}\")\n",
    "        print(f\"Scene Description: {scene['description']}\")\n",
    "        print(f\"Style Query: \\\"{scene['style_query']}\\\"\")\n",
    "\n",
    "        # Get style recommendations for this scene\n",
    "        recommendations = rag_engine.recommend_style(image, scene['style_query'])\n",
    "\n",
    "        # Display the top recommendation\n",
    "        if recommendations:\n",
    "            top_rec = recommendations[0]\n",
    "            print(f\"\\nRecommended Style: {top_rec['style']} (Score: {top_rec['score']})\")\n",
    "            print(f\"Style Description: {top_rec['description']}\")\n",
    "            print(\"Reasoning:\")\n",
    "            for reason in top_rec['reasoning']:\n",
    "                print(f\"- {reason}\")\n",
    "\n",
    "            # Apply the style\n",
    "            styled_image = rag_engine.apply_style(image, top_rec['style'])\n",
    "\n",
    "            # Display the result\n",
    "            display_before_after(image, styled_image, \n",
    "                               [\"Original Image\", f\"{scene['scene_name']} with '{top_rec['style']}' style\"])\n",
    "\n",
    "# Run the storytelling demonstration\n",
    "style_based_storytelling()\n"
   ],
   "id": "6d45a86f0970569"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Part 4: Innovative Use Case - AI-Guided Creative Photography\n",
    "\n",
    "Now let's explore an innovative use case that combines all of these AI capabilities: AI-guided creative photography. In this scenario, the AI analyzes an image, suggests creative directions, and helps the user achieve a specific artistic vision.\n",
    "\n",
    "This approach is particularly valuable for:\n",
    "- Amateur photographers looking to achieve professional results\n",
    "- Creative professionals seeking inspiration\n",
    "- Educators teaching photography and editing techniques\n",
    "\n",
    "Let's see how this works in practice.\n"
   ],
   "id": "cfe1b29592424bb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def ai_guided_creative_workflow(image, creative_direction):\n",
    "    \"\"\"Demonstrate an AI-guided creative workflow.\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        creative_direction: Description of the desired creative direction\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (final image, workflow steps)\n",
    "    \"\"\"\n",
    "    workflow_steps = []\n",
    "    results = [image.copy()]\n",
    "\n",
    "    # Step 1: Analyze the image\n",
    "    ai_analyzer = AIImageAnalyzer()\n",
    "    adjustments, analysis = ai_analyzer.analyze(image)\n",
    "\n",
    "    workflow_steps.append({\n",
    "        \"step\": \"Image Analysis\",\n",
    "        \"description\": f\"AI analyzed the image and identified it as a {analysis['scene_type']} scene with {analysis['lighting_condition']} lighting.\"\n",
    "    })\n",
    "\n",
    "    # Step 2: Apply basic adjustments\n",
    "    basic_adjusted = apply_adjustments(image, adjustments)\n",
    "    results.append(basic_adjusted)\n",
    "\n",
    "    workflow_steps.append({\n",
    "        \"step\": \"Basic Adjustments\",\n",
    "        \"description\": f\"Applied {len(adjustments)} AI-recommended adjustments to optimize the image.\"\n",
    "    })\n",
    "\n",
    "    # Step 3: Find styles matching the creative direction\n",
    "    rag_engine = RAGStyleEngine()\n",
    "    style_recs = rag_engine.recommend_style(image, creative_direction)\n",
    "\n",
    "    if style_recs:\n",
    "        # Apply the top recommended style\n",
    "        top_style = style_recs[0]['style']\n",
    "        styled_image = rag_engine.apply_style(basic_adjusted, top_style)\n",
    "        results.append(styled_image)\n",
    "\n",
    "        workflow_steps.append({\n",
    "            \"step\": \"Style Application\",\n",
    "            \"description\": f\"Applied '{top_style}' style based on the creative direction: '{creative_direction}'\"\n",
    "        })\n",
    "\n",
    "    # Step 4: Fine-tune with natural language processing\n",
    "    nl_processor = NLProcessor()\n",
    "\n",
    "    # Register the same functions as before\n",
    "    nl_processor.register_function(\"adjust_exposure\", adjust_exposure, \n",
    "                                 \"Adjust the brightness/exposure of the image\",\n",
    "                                 {\"amount\": {\"type\": \"number\", \"description\": \"Amount to adjust exposure (-1.0 to 1.0)\"}})\n",
    "\n",
    "    nl_processor.register_function(\"adjust_contrast\", adjust_contrast,\n",
    "                                 \"Adjust the contrast of the image\",\n",
    "                                 {\"multiplier\": {\"type\": \"number\", \"description\": \"Contrast multiplier (0.5 to 2.0)\"}})\n",
    "\n",
    "    nl_processor.register_function(\"adjust_saturation\", adjust_saturation,\n",
    "                                 \"Adjust the color saturation of the image\",\n",
    "                                 {\"adjustment\": {\"type\": \"number\", \"description\": \"Saturation adjustment (-1.0 to 1.0)\"}})\n",
    "\n",
    "    nl_processor.register_function(\"adjust_temperature\", adjust_temperature,\n",
    "                                 \"Adjust the color temperature (warmth/coolness) of the image\",\n",
    "                                 {\"adjustment\": {\"type\": \"number\", \"description\": \"Temperature adjustment (-0.5 to 0.5)\"}})\n",
    "\n",
    "    nl_processor.register_function(\"adjust_sharpness\", adjust_sharpness,\n",
    "                                 \"Adjust the sharpness/clarity of the image\",\n",
    "                                 {\"strength\": {\"type\": \"number\", \"description\": \"Sharpness strength (0.0 to 1.0)\"}})\n",
    "\n",
    "    nl_processor.register_function(\"reduce_noise\", reduce_noise,\n",
    "                                 \"Reduce noise/grain in the image\",\n",
    "                                 {\"strength\": {\"type\": \"number\", \"description\": \"Noise reduction strength (0.0 to 1.0)\"}})\n",
    "\n",
    "    # Generate a fine-tuning instruction based on the creative direction\n",
    "    fine_tuning_instruction = f\"Fine-tune for {creative_direction}\"\n",
    "    final_image, metadata = nl_processor.process(results[-1], fine_tuning_instruction)\n",
    "    results.append(final_image)\n",
    "\n",
    "    workflow_steps.append({\n",
    "        \"step\": \"Fine-tuning\",\n",
    "        \"description\": f\"Applied natural language fine-tuning: '{fine_tuning_instruction}'\",\n",
    "        \"functions\": [f\"{func['name']}({', '.join([f'{k}={v}' for k, v in func['args'].items()])})\" \n",
    "                     for func in metadata['functions_called']]\n",
    "    })\n",
    "\n",
    "    return final_image, results, workflow_steps\n"
   ],
   "id": "4308c807efdfc00b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Try the AI-guided creative workflow with different creative directions\n",
    "creative_directions = [\n",
    "    \"dramatic cinematic look\",\n",
    "    \"warm vintage feel\",\n",
    "    \"professional portrait style\"\n",
    "]\n",
    "\n",
    "for direction in creative_directions:\n",
    "    print(f\"\\n\\n=== AI-Guided Creative Workflow: '{direction}' ===\\n\")\n",
    "\n",
    "    final_image, workflow_images, steps = ai_guided_creative_workflow(image, direction)\n",
    "\n",
    "    # Display the workflow steps\n",
    "    for i, step in enumerate(steps):\n",
    "        print(f\"\\nStep {i+1}: {step['step']}\")\n",
    "        print(f\"  {step['description']}\")\n",
    "        if 'functions' in step:\n",
    "            print(\"  Functions applied:\")\n",
    "            for func in step['functions']:\n",
    "                print(f\"  - {func}\")\n",
    "\n",
    "    # Display the workflow images\n",
    "    step_titles = [\"Original\"] + [step[\"step\"] for step in steps]\n",
    "    display_multiple(workflow_images, step_titles)\n"
   ],
   "id": "e1e016dfa2615bb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "In this comprehensive notebook, we've demonstrated how generative AI transforms the photo editing experience by making it more accessible, intelligent, and efficient. We've explored three key innovations:\n",
    "\n",
    "1. **AI-powered image analysis** that understands content and recommends appropriate adjustments\n",
    "2. **Natural language photo editing** that allows users to describe what they want in plain English\n",
    "3. **RAG-based style recommendations** that suggest cinematic styles based on image content and user descriptions\n",
    "\n",
    "We've also shown how these capabilities can be combined in an **AI-guided creative workflow** that helps users achieve specific artistic visions.\n",
    "\n",
    "These AI-powered approaches democratize photo editing by removing the technical barriers that traditionally made it difficult for casual photographers to achieve professional-looking results. By understanding what's in the photo and what the user wants to achieve, the AI can guide them through the editing process and help them create images that match their creative vision.\n",
    "\n",
    "Key benefits include:\n",
    "\n",
    "- **Accessibility**: No technical knowledge required to achieve professional results\n",
    "- **Efficiency**: Faster editing with fewer steps and trial-and-error\n",
    "- **Intuitiveness**: Edit using familiar language instead of technical controls\n",
    "- **Education**: Learn about cinematography techniques and visual aesthetics\n",
    "- **Personalization**: Get recommendations tailored to specific image content\n",
    "\n",
    "The future of photo editing is not about replacing human creativity, but about augmenting it with AI that understands both the technical aspects of photography and the artistic intentions of the user.\n"
   ],
   "id": "59818d328aeefaf4"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
